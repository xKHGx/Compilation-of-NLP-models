{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11650,"sourceType":"datasetVersion","datasetId":8327},{"sourceId":2808848,"sourceType":"datasetVersion","datasetId":1709217}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Compilation of NLP models","metadata":{}},{"cell_type":"markdown","source":"## Outline\n\nExplore the following NLP models:\n- Simple RNNs\n- Word Embeddings\n- LSTM\n- GRU\n- Bi-Directional RNNs\n- Encoder-Decoder Models\n- Transformer/ Attention Models (DistilBERT)\n\nReferenced sources\n- Notebook #1 : https://www.kaggle.com/code/tanulsingh077/deep-learning-for-nlp-zero-to-transformers-bert/notebook\n- Notebook #2: https://www.kaggle.com/code/abhishek/approaching-almost-any-nlp-problem-on-kaggle\n- Notebook #3: https://www.kaggle.com/code/pranavmoothedath/real-nlp\n- Dataset: https://www.kaggle.com/competitions/jigsaw-multilingual-toxic-comment-classification/overview","metadata":{}},{"cell_type":"code","source":"# EDA tools\nimport pandas as pd\nimport numpy as np\nimport itertools\nimport datetime as dt\n\n# display and tracking of iterative processes\nfrom tqdm import tqdm\n\n# plotting tools\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# xgb\nimport xgboost as xgb\n\n# sklearn tools\nfrom sklearn.metrics import mean_squared_error, roc_auc_score\nfrom sklearn.model_selection import TimeSeriesSplit, GridSearchCV\nfrom sklearn.preprocessing import MinMaxScaler, StandardScaler\nfrom sklearn.model_selection import train_test_split\n\n# TensorFlow/ Keras\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing import sequence, text\nfrom tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras.layers import LSTM, GRU, SimpleRNN, Dense, Activation, Dropout, Embedding, Bidirectional, Input, Lambda\n\n# transformer\nimport transformers\nfrom transformers import TFDistilBertModel, DistilBertTokenizer\n\n# BERT Tokenizers\nfrom tokenizers import BertWordPieceTokenizer\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T02:24:53.163905Z","iopub.execute_input":"2024-11-24T02:24:53.164321Z","iopub.status.idle":"2024-11-24T02:24:53.175864Z","shell.execute_reply.started":"2024-11-24T02:24:53.164284Z","shell.execute_reply":"2024-11-24T02:24:53.175087Z"}},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"### Configuring TPU","metadata":{}},{"cell_type":"code","source":"# Detect hardware, return appropriate distribution strategy\ntry:\n    # TPU detection. No parameters necessary if TPU_NAME environment variable is\n    # set: this is always the case on Kaggle.\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    print('Running on TPU ', tpu.master())\nexcept ValueError:\n    tpu = None\n\n    \nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nelse:\n    # Default distribution strategy in Tensorflow. Works on CPU and single GPU.\n    strategy = tf.distribute.get_strategy()\n\nprint(\"REPLICAS: \", strategy.num_replicas_in_sync)","metadata":{"execution":{"iopub.status.busy":"2024-11-24T02:24:53.177051Z","iopub.execute_input":"2024-11-24T02:24:53.177307Z","iopub.status.idle":"2024-11-24T02:24:53.193027Z","shell.execute_reply.started":"2024-11-24T02:24:53.177283Z","shell.execute_reply":"2024-11-24T02:24:53.192181Z"},"trusted":true},"outputs":[{"name":"stdout","text":"REPLICAS:  1\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"### Import and check data","metadata":{}},{"cell_type":"code","source":"# import and check data\ntrain_df = pd.read_csv('/kaggle/input/jigsaw-multilingual-toxic-comment-classification/jigsaw-toxic-comment-train.csv')\nvalidation_df = pd.read_csv('/kaggle/input/jigsaw-multilingual-toxic-comment-classification/validation.csv')\ntest_df = pd.read_csv('/kaggle/input/jigsaw-multilingual-toxic-comment-classification/test.csv')\nsub_df = pd.read_csv('/kaggle/input/jigsaw-multilingual-toxic-comment-classification/sample_submission.csv')","metadata":{"execution":{"iopub.status.busy":"2024-11-24T02:24:53.193920Z","iopub.execute_input":"2024-11-24T02:24:53.194163Z","iopub.status.idle":"2024-11-24T02:24:56.537736Z","shell.execute_reply.started":"2024-11-24T02:24:53.194139Z","shell.execute_reply":"2024-11-24T02:24:56.536789Z"},"trusted":true},"outputs":[],"execution_count":3},{"cell_type":"code","source":"train_df.info()\nvalidation_df.info()\ntest_df.info()","metadata":{"execution":{"iopub.status.busy":"2024-11-24T02:24:56.540264Z","iopub.execute_input":"2024-11-24T02:24:56.540632Z","iopub.status.idle":"2024-11-24T02:24:56.631665Z","shell.execute_reply.started":"2024-11-24T02:24:56.540592Z","shell.execute_reply":"2024-11-24T02:24:56.630859Z"},"trusted":true},"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 223549 entries, 0 to 223548\nData columns (total 8 columns):\n #   Column         Non-Null Count   Dtype \n---  ------         --------------   ----- \n 0   id             223549 non-null  object\n 1   comment_text   223549 non-null  object\n 2   toxic          223549 non-null  int64 \n 3   severe_toxic   223549 non-null  int64 \n 4   obscene        223549 non-null  int64 \n 5   threat         223549 non-null  int64 \n 6   insult         223549 non-null  int64 \n 7   identity_hate  223549 non-null  int64 \ndtypes: int64(6), object(2)\nmemory usage: 13.6+ MB\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 8000 entries, 0 to 7999\nData columns (total 4 columns):\n #   Column        Non-Null Count  Dtype \n---  ------        --------------  ----- \n 0   id            8000 non-null   int64 \n 1   comment_text  8000 non-null   object\n 2   lang          8000 non-null   object\n 3   toxic         8000 non-null   int64 \ndtypes: int64(2), object(2)\nmemory usage: 250.1+ KB\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 63812 entries, 0 to 63811\nData columns (total 3 columns):\n #   Column   Non-Null Count  Dtype \n---  ------   --------------  ----- \n 0   id       63812 non-null  int64 \n 1   content  63812 non-null  object\n 2   lang     63812 non-null  object\ndtypes: int64(1), object(2)\nmemory usage: 1.5+ MB\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"train_df.isna().sum()\n# validation_df.isna().sum()\n# test_df.isna().sum()","metadata":{"execution":{"iopub.status.busy":"2024-11-24T02:24:56.632739Z","iopub.execute_input":"2024-11-24T02:24:56.633021Z","iopub.status.idle":"2024-11-24T02:24:56.676748Z","shell.execute_reply.started":"2024-11-24T02:24:56.632996Z","shell.execute_reply":"2024-11-24T02:24:56.675778Z"},"trusted":true},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"id               0\ncomment_text     0\ntoxic            0\nsevere_toxic     0\nobscene          0\nthreat           0\ninsult           0\nidentity_hate    0\ndtype: int64"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"# train_df.head(3)\n# validation_df.head(3)\ntest_df.head(3)","metadata":{"execution":{"iopub.status.busy":"2024-11-24T02:24:56.677843Z","iopub.execute_input":"2024-11-24T02:24:56.678163Z","iopub.status.idle":"2024-11-24T02:24:56.693958Z","shell.execute_reply.started":"2024-11-24T02:24:56.678136Z","shell.execute_reply":"2024-11-24T02:24:56.693151Z"},"trusted":true},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"   id                                            content lang\n0   0  Doctor Who adlı viki başlığına 12. doctor olar...   tr\n1   1   Вполне возможно, но я пока не вижу необходимо...   ru\n2   2  Quindi tu sei uno di quelli   conservativi  , ...   it","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>content</th>\n      <th>lang</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>Doctor Who adlı viki başlığına 12. doctor olar...</td>\n      <td>tr</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>Вполне возможно, но я пока не вижу необходимо...</td>\n      <td>ru</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>Quindi tu sei uno di quelli   conservativi  , ...</td>\n      <td>it</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":6},{"cell_type":"markdown","source":"### Approach: Binary Classification of topic toxicity","metadata":{}},{"cell_type":"code","source":"# drop all columns except for 'toxic'\n\ntrain_df.drop(columns = ['severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate'], inplace= True)","metadata":{"execution":{"iopub.status.busy":"2024-11-24T02:24:56.695108Z","iopub.execute_input":"2024-11-24T02:24:56.695439Z","iopub.status.idle":"2024-11-24T02:24:56.715262Z","shell.execute_reply.started":"2024-11-24T02:24:56.695403Z","shell.execute_reply":"2024-11-24T02:24:56.714348Z"},"trusted":true},"outputs":[],"execution_count":7},{"cell_type":"code","source":"train_df.head(3)","metadata":{"execution":{"iopub.status.busy":"2024-11-24T02:24:56.716203Z","iopub.execute_input":"2024-11-24T02:24:56.716468Z","iopub.status.idle":"2024-11-24T02:24:56.724023Z","shell.execute_reply.started":"2024-11-24T02:24:56.716443Z","shell.execute_reply":"2024-11-24T02:24:56.723082Z"},"trusted":true},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"                 id                                       comment_text  toxic\n0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0\n1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0\n2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>comment_text</th>\n      <th>toxic</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0000997932d777bf</td>\n      <td>Explanation\\nWhy the edits made under my usern...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>000103f0d9cfb60f</td>\n      <td>D'aww! He matches this background colour I'm s...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>000113f07ec002fd</td>\n      <td>Hey man, I'm really not trying to edit war. It...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"# check for feature skewness\ntrain_df['toxic'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2024-11-24T02:24:56.725356Z","iopub.execute_input":"2024-11-24T02:24:56.725619Z","iopub.status.idle":"2024-11-24T02:24:56.743458Z","shell.execute_reply.started":"2024-11-24T02:24:56.725595Z","shell.execute_reply":"2024-11-24T02:24:56.742375Z"},"trusted":true},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"toxic\n0    202165\n1     21384\nName: count, dtype: int64"},"metadata":{}}],"execution_count":9},{"cell_type":"markdown","source":"### EDA","metadata":{}},{"cell_type":"code","source":"# max word count in a comment\nmax_length = train_df['comment_text'].map(lambda x: len(x.split())).max()\nmax_length","metadata":{"execution":{"iopub.status.busy":"2024-11-24T02:24:56.747206Z","iopub.execute_input":"2024-11-24T02:24:56.747453Z","iopub.status.idle":"2024-11-24T02:24:57.699817Z","shell.execute_reply.started":"2024-11-24T02:24:56.747428Z","shell.execute_reply":"2024-11-24T02:24:57.698787Z"},"trusted":true},"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"2321"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"# min word count in a comment\ntrain_df['comment_text'].map(lambda x: len(x.split())).min()","metadata":{"execution":{"iopub.status.busy":"2024-11-24T02:24:57.701098Z","iopub.execute_input":"2024-11-24T02:24:57.701480Z","iopub.status.idle":"2024-11-24T02:24:58.588673Z","shell.execute_reply.started":"2024-11-24T02:24:57.701441Z","shell.execute_reply":"2024-11-24T02:24:58.587763Z"},"trusted":true},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"1"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"# add feature: word count\ntrain_df['word_count'] = train_df['comment_text'].map(lambda x: len(x.split()))","metadata":{"execution":{"iopub.status.busy":"2024-11-24T02:24:58.589889Z","iopub.execute_input":"2024-11-24T02:24:58.590225Z","iopub.status.idle":"2024-11-24T02:24:59.487706Z","shell.execute_reply.started":"2024-11-24T02:24:58.590190Z","shell.execute_reply":"2024-11-24T02:24:59.486688Z"},"trusted":true},"outputs":[],"execution_count":12},{"cell_type":"code","source":"# groupby toxic comments and average word count difference\ntrain_df.groupby(['toxic']).agg({'word_count': 'mean'})","metadata":{"execution":{"iopub.status.busy":"2024-11-24T02:24:59.488849Z","iopub.execute_input":"2024-11-24T02:24:59.489198Z","iopub.status.idle":"2024-11-24T02:24:59.507085Z","shell.execute_reply.started":"2024-11-24T02:24:59.489159Z","shell.execute_reply":"2024-11-24T02:24:59.506194Z"},"trusted":true},"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"       word_count\ntoxic            \n0       68.415161\n1       48.573466","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>word_count</th>\n    </tr>\n    <tr>\n      <th>toxic</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>68.415161</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>48.573466</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":13},{"cell_type":"markdown","source":"Data suggest that toxic comments are straight to the point (e.g less word count).","metadata":{}},{"cell_type":"code","source":"train_df['comment_text'].values","metadata":{"execution":{"iopub.status.busy":"2024-11-24T02:24:59.508222Z","iopub.execute_input":"2024-11-24T02:24:59.508581Z","iopub.status.idle":"2024-11-24T02:24:59.521141Z","shell.execute_reply.started":"2024-11-24T02:24:59.508543Z","shell.execute_reply":"2024-11-24T02:24:59.520193Z"},"trusted":true},"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"array([\"Explanation\\nWhy the edits made under my username Hardcore Metallica Fan were reverted? They weren't vandalisms, just closure on some GAs after I voted at New York Dolls FAC. And please don't remove the template from the talk page since I'm retired now.89.205.38.27\",\n       \"D'aww! He matches this background colour I'm seemingly stuck with. Thanks.  (talk) 21:51, January 11, 2016 (UTC)\",\n       \"Hey man, I'm really not trying to edit war. It's just that this guy is constantly removing relevant information and talking to me through edits instead of my talk page. He seems to care more about the formatting than the actual info.\",\n       ...,\n       '==shame on you all!!!== \\n\\n You want to speak about gays and not about romanians...',\n       'MEL GIBSON IS A NAZI BITCH WHO MAKES SHITTY MOVIES. HE HAS SO MUCH BUTTSEX THAT HIS ASSHOLE IS NOW BIG ENOUGH TO BE CONSIDERED A COUNTRY.',\n       '\" \\n\\n == Unicorn lair discovery == \\n\\n Supposedly, a \\'unicorn lair\\' has been discovered in Pyongyang, North Korea. The lair is supposedly associated with King Dongmyeong of Goguryeo, who supposedly rode a unicorn.  It should be added, but i can\\'t quite find where to insert it. \"'],\n      dtype=object)"},"metadata":{}}],"execution_count":14},{"cell_type":"markdown","source":"### Train/Test Split","metadata":{}},{"cell_type":"code","source":"# shuffle default = True\nX_train, X_test, y_train, y_test = train_test_split(train_df['comment_text'].values, train_df['toxic'].values, test_size=0.25, stratify=train_df['toxic'], random_state=22)","metadata":{"execution":{"iopub.status.busy":"2024-11-24T02:24:59.522231Z","iopub.execute_input":"2024-11-24T02:24:59.522565Z","iopub.status.idle":"2024-11-24T02:24:59.647167Z","shell.execute_reply.started":"2024-11-24T02:24:59.522529Z","shell.execute_reply":"2024-11-24T02:24:59.645749Z"},"trusted":true},"outputs":[],"execution_count":15},{"cell_type":"markdown","source":"### Recurrent Neural Network","metadata":{}},{"cell_type":"markdown","source":"https://stackoverflow.com/questions/76029717/having-trouble-correctly-importing-tensorflow-tokenizer-and-tensorflow-padded-se","metadata":{}},{"cell_type":"code","source":"# tokenise data with keras.text.Tokenizer\n\ntoken = text.Tokenizer()","metadata":{"execution":{"iopub.status.busy":"2024-11-24T02:24:59.649885Z","iopub.execute_input":"2024-11-24T02:24:59.650128Z","iopub.status.idle":"2024-11-24T02:24:59.669660Z","shell.execute_reply.started":"2024-11-24T02:24:59.650104Z","shell.execute_reply":"2024-11-24T02:24:59.668643Z"},"trusted":true},"outputs":[],"execution_count":16},{"cell_type":"markdown","source":"### Fit the tokenizer to the text data","metadata":{}},{"cell_type":"code","source":"# fit tokenise on train data. fit_on_texts accept both array and list\ntoken.fit_on_texts(X_train)\n\n# maps word to corresponding index\nword_index = token.word_index","metadata":{"execution":{"iopub.status.busy":"2024-11-24T02:24:59.671001Z","iopub.execute_input":"2024-11-24T02:24:59.671592Z","iopub.status.idle":"2024-11-24T02:25:09.315508Z","shell.execute_reply.started":"2024-11-24T02:24:59.671552Z","shell.execute_reply":"2024-11-24T02:25:09.314547Z"},"trusted":true},"outputs":[],"execution_count":17},{"cell_type":"code","source":"# transform on X_train and X_test\nX_train_seq = token.texts_to_sequences(X_train)\nX_test_seq = token.texts_to_sequences(X_test)","metadata":{"execution":{"iopub.status.busy":"2024-11-24T02:25:09.316638Z","iopub.execute_input":"2024-11-24T02:25:09.316946Z","iopub.status.idle":"2024-11-24T02:25:17.630870Z","shell.execute_reply.started":"2024-11-24T02:25:09.316919Z","shell.execute_reply":"2024-11-24T02:25:17.630134Z"},"trusted":true},"outputs":[],"execution_count":18},{"cell_type":"code","source":"# pad data so that they are of uniform length, so neural network architectures can process sequential data\nX_train_pad = sequence.pad_sequences(X_train_seq, maxlen= max_length)\nX_test_pad = sequence.pad_sequences(X_test_seq, maxlen= max_length)","metadata":{"execution":{"iopub.status.busy":"2024-11-24T02:25:17.633183Z","iopub.execute_input":"2024-11-24T02:25:17.633433Z","iopub.status.idle":"2024-11-24T02:25:19.293297Z","shell.execute_reply.started":"2024-11-24T02:25:17.633409Z","shell.execute_reply":"2024-11-24T02:25:19.292487Z"},"trusted":true},"outputs":[],"execution_count":19},{"cell_type":"markdown","source":"### Simple RNN\n","metadata":{}},{"cell_type":"markdown","source":"### Determine embedding vector space dimension: https://ai.stackexchange.com/questions/28564/how-to-determine-the-embedding-size","metadata":{}},{"cell_type":"code","source":"# set embedding_dim\n# should embedding_dim == max_length == neurons?\n# Here, we have used an Embedding layer followed by an LSTM layer. The embedding layer takes the 32-dimensional vectors, each of which corresponds to a sentence, and subsequently outputs (32,32) dimensional matrices i.e., it creates a 32-dimensional vector corresponding to each word. This embedding is also learnt during model training.\n\nembedding_dim = 300","metadata":{"execution":{"iopub.status.busy":"2024-11-24T02:25:19.294829Z","iopub.execute_input":"2024-11-24T02:25:19.295143Z","iopub.status.idle":"2024-11-24T02:25:19.299308Z","shell.execute_reply.started":"2024-11-24T02:25:19.295113Z","shell.execute_reply":"2024-11-24T02:25:19.298292Z"},"trusted":true},"outputs":[],"execution_count":20},{"cell_type":"code","source":"# instantiate a sequential model\nmodel = Sequential()\n\n# turns indexes in to Dense vectors\n\nmodel.add(Embedding(\n    input_dim = len(word_index)+1, # match the number of unique words or tokens in your vocabulary.\n    output_dim = embedding_dim, # vector space dimensions. depends on the specific task, but common values range from 64 to 512. Equals to # of dimensional vector\n    input_length = max_length # maximum sequence length in your data\n))\n\n# add a Simple RNN layer of x neurons\nmodel.add(SimpleRNN(embedding_dim)) # 300 = number of neurons/ cells\n\n# add one Dense layer\nmodel.add(Dense(\n    1, # add one dense layer\n    activation = 'sigmoid' # add sigmoid activation layer\n))\n\nmodel.compile(\n    loss = 'binary_crossentropy',\n    optimizer = 'adam',\n    metrics = ['accuracy'], # tracked classification metric\n)\n\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2024-11-24T02:25:19.300703Z","iopub.execute_input":"2024-11-24T02:25:19.301111Z","iopub.status.idle":"2024-11-24T02:25:19.373577Z","shell.execute_reply.started":"2024-11-24T02:25:19.301069Z","shell.execute_reply":"2024-11-24T02:25:19.372749Z"},"trusted":true},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"sequential\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ simple_rnn (\u001b[38;5;33mSimpleRNN\u001b[0m)          │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ simple_rnn (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)          │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}}],"execution_count":21},{"cell_type":"code","source":"model.fit(X_train_pad, y_train, epochs=2, batch_size=512)","metadata":{"execution":{"iopub.status.busy":"2024-11-24T02:25:19.374521Z","iopub.execute_input":"2024-11-24T02:25:19.374770Z","iopub.status.idle":"2024-11-24T02:33:53.861528Z","shell.execute_reply.started":"2024-11-24T02:25:19.374744Z","shell.execute_reply":"2024-11-24T02:33:53.860677Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Epoch 1/2\n","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1732415126.587556      70 service.cc:145] XLA service 0x5c882f9c5b70 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\nI0000 00:00:1732415126.587658      70 service.cc:153]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\nI0000 00:00:1732415127.647757      70 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m260s\u001b[0m 772ms/step - accuracy: 0.9086 - loss: 0.2784\nEpoch 2/2\n\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m253s\u001b[0m 770ms/step - accuracy: 0.9324 - loss: 0.2075\n","output_type":"stream"},{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.history.History at 0x7a39ab9c7310>"},"metadata":{}}],"execution_count":22},{"cell_type":"markdown","source":"### Predict test result","metadata":{}},{"cell_type":"code","source":"# predict = model.predict_proba(X_test_pad)[:,0]\npredict = model.predict(X_test_pad)[:,0]","metadata":{"execution":{"iopub.status.busy":"2024-11-24T02:33:53.862554Z","iopub.execute_input":"2024-11-24T02:33:53.862915Z","iopub.status.idle":"2024-11-24T02:35:54.824487Z","shell.execute_reply.started":"2024-11-24T02:33:53.862886Z","shell.execute_reply":"2024-11-24T02:35:54.823775Z"},"trusted":true},"outputs":[{"name":"stdout","text":"\u001b[1m1747/1747\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 68ms/step\n","output_type":"stream"}],"execution_count":23},{"cell_type":"markdown","source":"### AUC Score","metadata":{}},{"cell_type":"code","source":"# track auc scores\nauc_scores = []","metadata":{"execution":{"iopub.status.busy":"2024-11-24T02:35:54.825811Z","iopub.execute_input":"2024-11-24T02:35:54.826094Z","iopub.status.idle":"2024-11-24T02:35:54.830310Z","shell.execute_reply.started":"2024-11-24T02:35:54.826067Z","shell.execute_reply":"2024-11-24T02:35:54.829282Z"},"trusted":true},"outputs":[],"execution_count":24},{"cell_type":"code","source":"# append SimpleRnn auc score\nauc_scores.append({'Model':'SimpleRnn', 'AUC_Score':round(roc_auc_score(y_test,predict),4)})\nprint(f'auc: {roc_auc_score(y_test,predict):.4f}')","metadata":{"execution":{"iopub.status.busy":"2024-11-24T02:35:54.831149Z","iopub.execute_input":"2024-11-24T02:35:54.831420Z","iopub.status.idle":"2024-11-24T02:35:54.894096Z","shell.execute_reply.started":"2024-11-24T02:35:54.831395Z","shell.execute_reply":"2024-11-24T02:35:54.893417Z"},"trusted":true},"outputs":[{"name":"stdout","text":"auc: 0.8893\n","output_type":"stream"}],"execution_count":25},{"cell_type":"markdown","source":"### Use pre-trained word embeddings instead of training from scratch","metadata":{}},{"cell_type":"markdown","source":"1. Visualisation of embedding vectors: https://www.kaggle.com/code/auxeno/word-embedding-visualisations-nlp\n2. Load GloVe Embeddings - Standford GloVe link: https://nlp.stanford.edu/projects/glove/\n","metadata":{}},{"cell_type":"code","source":"# load the GloVe vectors in a dictionary:\n\nembeddings_index = {}\nf = open('/kaggle/input/glove840b300dtxt/glove.840B.300d.txt','r',encoding='utf-8')\nfor line in tqdm(f):\n    values = line.split(' ')\n    word = values[0]\n    coefs = np.array([float(val) for val in values[1:]])\n    embeddings_index[word] = coefs\nf.close()\n\nprint(f'Found {len(embeddings_index)} word vectors')","metadata":{"execution":{"iopub.status.busy":"2024-11-24T02:35:54.895064Z","iopub.execute_input":"2024-11-24T02:35:54.895312Z","iopub.status.idle":"2024-11-24T02:38:52.282652Z","shell.execute_reply.started":"2024-11-24T02:35:54.895289Z","shell.execute_reply":"2024-11-24T02:38:52.281723Z"},"trusted":true},"outputs":[{"name":"stderr","text":"2196018it [02:56, 12423.62it/s]","output_type":"stream"},{"name":"stdout","text":"Found 2196017 word vectors\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":26},{"cell_type":"markdown","source":"### LSTM - Advance RNN with memory cells and gates. Address vanishing gradient problems.","metadata":{}},{"cell_type":"code","source":"# creating embedding matrix of 0s, in shape of row = len of word_index +1 ,and columns = vector space dimensions\n# loop through word_index, get the word and check if the word exist in embeddings_index (created from GloVe Vectors)\n# if yes, assign corresponding GloVe vector to word index\n\nembeddings_matrix = np.zeros((len(word_index) + 1, 300))\n\nfor word, i in tqdm(word_index.items()):\n    embeddings_vector = embeddings_index.get(word)\n    if embeddings_vector is not None:\n        embeddings_matrix[i] = embeddings_vector\n","metadata":{"execution":{"iopub.status.busy":"2024-11-24T02:38:52.283791Z","iopub.execute_input":"2024-11-24T02:38:52.284037Z","iopub.status.idle":"2024-11-24T02:38:52.981877Z","shell.execute_reply.started":"2024-11-24T02:38:52.284013Z","shell.execute_reply":"2024-11-24T02:38:52.981059Z"},"trusted":true},"outputs":[{"name":"stderr","text":"100%|██████████| 248872/248872 [00:00<00:00, 360774.41it/s]\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"embeddings_matrix","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T02:38:52.986079Z","iopub.execute_input":"2024-11-24T02:38:52.986362Z","iopub.status.idle":"2024-11-24T02:38:52.992568Z","shell.execute_reply.started":"2024-11-24T02:38:52.986335Z","shell.execute_reply":"2024-11-24T02:38:52.991761Z"}},"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"array([[ 0.      ,  0.      ,  0.      , ...,  0.      ,  0.      ,\n         0.      ],\n       [ 0.27204 , -0.06203 , -0.1884  , ...,  0.13015 , -0.18317 ,\n         0.1323  ],\n       [ 0.31924 ,  0.06316 , -0.27858 , ...,  0.082745,  0.097801,\n         0.25045 ],\n       ...,\n       [ 0.      ,  0.      ,  0.      , ...,  0.      ,  0.      ,\n         0.      ],\n       [ 0.56065 ,  0.20414 , -0.076262, ...,  0.061545,  0.81221 ,\n        -0.8306  ],\n       [ 0.      ,  0.      ,  0.      , ...,  0.      ,  0.      ,\n         0.      ]])"},"metadata":{}}],"execution_count":28},{"cell_type":"markdown","source":"### LSTM Model","metadata":{}},{"cell_type":"code","source":"# initialise a sequential model\nmodel = Sequential()\n\n# Add Embedding as the first layer\n# Use embedding matrix as weights instead of training again\nmodel.add(Embedding(\n    len(word_index)+1,\n    embedding_dim, # should vector space dimension tie to model input?\n    weights = [embeddings_matrix],\n    input_length = max_length,\n    trainable = False # set trainable to False so we dont retrain model again\n))\n\n# Add LSTM layers\nmodel.add(LSTM(\n    embedding_dim, # should it tie to Embedding vector space dimension?\n    dropout = 0.3,\n    recurrent_dropout = 0.3\n))\n\n# Add Dense layer\nmodel.add(Dense(\n    1, \n    activation = 'sigmoid'\n))\n\n# Compile model with loss function and optimiser\nmodel.compile(\n    loss = 'binary_crossentropy',\n    optimizer = 'adam',\n    metrics = ['accuracy'] # tracked metrics. one can have multiple metrices in a list\n)\n\nmodel.summary()\n","metadata":{"execution":{"iopub.status.busy":"2024-11-24T02:38:52.993528Z","iopub.execute_input":"2024-11-24T02:38:52.993787Z","iopub.status.idle":"2024-11-24T02:38:54.176525Z","shell.execute_reply.started":"2024-11-24T02:38:52.993762Z","shell.execute_reply":"2024-11-24T02:38:54.175812Z"},"trusted":true},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"sequential_1\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)         │ ?                      │    \u001b[38;5;34m74,661,900\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ ?                      │    <span style=\"color: #00af00; text-decoration-color: #00af00\">74,661,900</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m74,661,900\u001b[0m (284.81 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">74,661,900</span> (284.81 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m74,661,900\u001b[0m (284.81 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">74,661,900</span> (284.81 MB)\n</pre>\n"},"metadata":{}}],"execution_count":29},{"cell_type":"code","source":"model.fit(X_train_pad, y_train, epochs=2, batch_size=256)","metadata":{"execution":{"iopub.status.busy":"2024-11-24T02:38:54.177539Z","iopub.execute_input":"2024-11-24T02:38:54.177840Z","iopub.status.idle":"2024-11-24T03:39:13.821736Z","shell.execute_reply.started":"2024-11-24T02:38:54.177813Z","shell.execute_reply":"2024-11-24T03:39:13.820769Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Epoch 1/2\n\u001b[1m655/655\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1809s\u001b[0m 3s/step - accuracy: 0.9329 - loss: 0.1840\nEpoch 2/2\n\u001b[1m655/655\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1808s\u001b[0m 3s/step - accuracy: 0.9536 - loss: 0.1187\n","output_type":"stream"},{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.history.History at 0x7a396c997220>"},"metadata":{}}],"execution_count":30},{"cell_type":"code","source":"predict = model.predict(X_test_pad)[:,0]","metadata":{"execution":{"iopub.status.busy":"2024-11-24T03:39:13.823244Z","iopub.execute_input":"2024-11-24T03:39:13.823541Z","iopub.status.idle":"2024-11-24T04:03:29.502635Z","shell.execute_reply.started":"2024-11-24T03:39:13.823512Z","shell.execute_reply":"2024-11-24T04:03:29.501596Z"},"trusted":true},"outputs":[{"name":"stdout","text":"\u001b[1m1747/1747\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1454s\u001b[0m 832ms/step\n","output_type":"stream"}],"execution_count":31},{"cell_type":"code","source":"# append LSTM auc score\nauc_scores.append({'Model': 'LSTM', 'AUC_Score': round(roc_auc_score(y_test,predict),4)})\nprint(f'auc: {roc_auc_score(y_test,predict):.4f}')","metadata":{"execution":{"iopub.status.busy":"2024-11-24T04:03:29.504403Z","iopub.execute_input":"2024-11-24T04:03:29.505120Z","iopub.status.idle":"2024-11-24T04:03:29.550370Z","shell.execute_reply.started":"2024-11-24T04:03:29.505077Z","shell.execute_reply":"2024-11-24T04:03:29.549629Z"},"trusted":true},"outputs":[{"name":"stdout","text":"auc: 0.9769\n","output_type":"stream"}],"execution_count":32},{"cell_type":"markdown","source":"### Gated Recurrent Unit - GRU\n1. Design to solve vanishing gradient problem. Similar to LSTM.\n2. Update Gate: How much information to pass along to the future\n3. Reset Gate: How much information of past information to forget","metadata":{}},{"cell_type":"code","source":"# with strategy.scope():\n    \n# initialise a sequential model\nmodel = Sequential()\n\n# Add Embedding as the first layer\n# Use embedding matrix as weights instead of training again\nmodel.add(Embedding(\n    len(word_index)+1,\n    embedding_dim,\n    weights = [embeddings_matrix],\n    input_length = max_length,\n    trainable = False # set trainable to False so we dont retrain model again\n))\n\n# Add GRU layers\nmodel.add(GRU(\n    embedding_dim,\n    dropout = 0.3,\n    # recurrent_dropout = 0.3 #issue with losses: NaN is this is active\n))\n\n# Add Dense layer\nmodel.add(Dense(\n    1, \n    activation = 'sigmoid'\n))\n\n# Compile model with loss function and optimiser\nmodel.compile(\n    loss = 'binary_crossentropy',\n    optimizer = 'adam',\n    metrics = ['accuracy'] # tracked metrics. one can have multiple metrices in a list\n)\n\nmodel.summary()\n    ","metadata":{"execution":{"iopub.status.busy":"2024-11-24T04:03:29.551308Z","iopub.execute_input":"2024-11-24T04:03:29.551565Z","iopub.status.idle":"2024-11-24T04:03:30.250433Z","shell.execute_reply.started":"2024-11-24T04:03:29.551540Z","shell.execute_reply":"2024-11-24T04:03:30.249700Z"},"trusted":true},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"sequential_2\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ embedding_2 (\u001b[38;5;33mEmbedding\u001b[0m)         │ ?                      │    \u001b[38;5;34m74,661,900\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ gru (\u001b[38;5;33mGRU\u001b[0m)                       │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ embedding_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ ?                      │    <span style=\"color: #00af00; text-decoration-color: #00af00\">74,661,900</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ gru (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                       │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m74,661,900\u001b[0m (284.81 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">74,661,900</span> (284.81 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m74,661,900\u001b[0m (284.81 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">74,661,900</span> (284.81 MB)\n</pre>\n"},"metadata":{}}],"execution_count":33},{"cell_type":"code","source":"model.fit(X_train_pad, y_train, epochs=2, batch_size=256)","metadata":{"execution":{"iopub.status.busy":"2024-11-24T04:03:30.251358Z","iopub.execute_input":"2024-11-24T04:03:30.251597Z","iopub.status.idle":"2024-11-24T05:15:11.096409Z","shell.execute_reply.started":"2024-11-24T04:03:30.251573Z","shell.execute_reply":"2024-11-24T05:15:11.095538Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Epoch 1/2\n\u001b[1m655/655\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2152s\u001b[0m 3s/step - accuracy: 0.9318 - loss: 0.1764\nEpoch 2/2\n\u001b[1m655/655\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2147s\u001b[0m 3s/step - accuracy: 0.9562 - loss: 0.1097\n","output_type":"stream"},{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.history.History at 0x7a3984ad5210>"},"metadata":{}}],"execution_count":34},{"cell_type":"code","source":"# predict = model.predict_proba(X_test_pad)[:,0]\npredict = model.predict(X_test_pad)[:,0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T05:15:11.097485Z","iopub.execute_input":"2024-11-24T05:15:11.097813Z","iopub.status.idle":"2024-11-24T05:41:56.218697Z","shell.execute_reply.started":"2024-11-24T05:15:11.097769Z","shell.execute_reply":"2024-11-24T05:41:56.217977Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m1747/1747\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1604s\u001b[0m 918ms/step\n","output_type":"stream"}],"execution_count":35},{"cell_type":"code","source":"# append GRU auc score\nauc_scores.append({'Model': 'GRU', 'AUC_Score':round(roc_auc_score(y_test,predict),4)})\nprint(f'auc: {roc_auc_score(y_test,predict):.4f}')","metadata":{"execution":{"iopub.status.busy":"2024-11-24T05:41:56.220473Z","iopub.execute_input":"2024-11-24T05:41:56.220952Z","iopub.status.idle":"2024-11-24T05:41:56.265659Z","shell.execute_reply.started":"2024-11-24T05:41:56.220910Z","shell.execute_reply":"2024-11-24T05:41:56.264870Z"},"trusted":true},"outputs":[{"name":"stdout","text":"auc: 0.9786\n","output_type":"stream"}],"execution_count":36},{"cell_type":"markdown","source":"### Bi-Directional RNN\n\nTwo independent RNNs. #1 with input sequence in normal time order. #2 with input sequence in reverse time order.\n\nOutputs of two networks are concatenated or summed at each time steps, depending on options.\n\nAllow networks to have both forward and backward information about the sequence at each time step.","metadata":{}},{"cell_type":"code","source":"# with strategy.scope():\n    \n# initialise a sequential model\nmodel = Sequential()\n\n# Add Embedding as the first layer\n# Use embedding matrix as weights instead of training again\nmodel.add(Embedding(\n    len(word_index)+1,\n    embedding_dim, # should this be the same as RNN/GRU/LSTM input?\n    weights = [embeddings_matrix],\n    input_length = max_length,\n    trainable = False # set trainable to False so we dont retrain model again\n))\n\n# Add Bidirectional RNN layers\nmodel.add(Bidirectional(LSTM(\n    embedding_dim, # this should tie to embedding \n    dropout = 0.3,\n    recurrent_dropout = 0.3\n)))\n\n# Add Dense layer\nmodel.add(Dense(\n    1, \n    activation = 'sigmoid'\n))\n\n# Compile model with loss function and optimiser\nmodel.compile(\n    loss = 'binary_crossentropy',\n    optimizer = 'adam',\n    metrics = ['accuracy'] # tracked metrics. one can have multiple metrices in a list\n)\n\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2024-11-24T05:41:56.266659Z","iopub.execute_input":"2024-11-24T05:41:56.266928Z","iopub.status.idle":"2024-11-24T05:41:56.978748Z","shell.execute_reply.started":"2024-11-24T05:41:56.266904Z","shell.execute_reply":"2024-11-24T05:41:56.977700Z"},"trusted":true},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"sequential_3\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ embedding_3 (\u001b[38;5;33mEmbedding\u001b[0m)         │ ?                      │    \u001b[38;5;34m74,661,900\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ embedding_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ ?                      │    <span style=\"color: #00af00; text-decoration-color: #00af00\">74,661,900</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m74,661,900\u001b[0m (284.81 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">74,661,900</span> (284.81 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m74,661,900\u001b[0m (284.81 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">74,661,900</span> (284.81 MB)\n</pre>\n"},"metadata":{}}],"execution_count":37},{"cell_type":"code","source":"model.fit(X_train_pad, y_train, epochs=2, batch_size=128)","metadata":{"execution":{"iopub.status.busy":"2024-11-24T05:41:56.980084Z","iopub.execute_input":"2024-11-24T05:41:56.980550Z","iopub.status.idle":"2024-11-24T08:36:17.521687Z","shell.execute_reply.started":"2024-11-24T05:41:56.980509Z","shell.execute_reply":"2024-11-24T08:36:17.520735Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Epoch 1/2\n\u001b[1m1310/1310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5221s\u001b[0m 4s/step - accuracy: 0.9350 - loss: 0.1767\nEpoch 2/2\n\u001b[1m1310/1310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5238s\u001b[0m 4s/step - accuracy: 0.9543 - loss: 0.1148\n","output_type":"stream"},{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.history.History at 0x7a3987c64bb0>"},"metadata":{}}],"execution_count":38},{"cell_type":"code","source":"predict = model.predict(X_test_pad)[:,0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T08:36:17.522994Z","iopub.execute_input":"2024-11-24T08:36:17.523287Z","iopub.status.idle":"2024-11-24T09:08:29.072940Z","shell.execute_reply.started":"2024-11-24T08:36:17.523260Z","shell.execute_reply":"2024-11-24T09:08:29.072185Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m1747/1747\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1930s\u001b[0m 1s/step\n","output_type":"stream"}],"execution_count":39},{"cell_type":"code","source":"# append Bi-Directional auc score\nauc_scores.append({'Model':'Bi-Directional', 'AUC_Score': round(roc_auc_score(y_test,predict),4)})\nprint(f'auc: {roc_auc_score(y_test,predict):.4f}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T09:08:29.074738Z","iopub.execute_input":"2024-11-24T09:08:29.075119Z","iopub.status.idle":"2024-11-24T09:08:29.120172Z","shell.execute_reply.started":"2024-11-24T09:08:29.075080Z","shell.execute_reply":"2024-11-24T09:08:29.119456Z"}},"outputs":[{"name":"stdout","text":"auc: 0.9773\n","output_type":"stream"}],"execution_count":40},{"cell_type":"markdown","source":"### Attention Models","metadata":{}},{"cell_type":"markdown","source":"### Relationship between BERT Tokens (max 512 tokens) and vector dimensions (768 vector dimensions):\n\nThe tensor contains 512 tokens, each with 768 values, representing contextual embeddings. The mean pooling process involves calculating the average of all token embeddings, effectively consolidating them into a single 768-dimensional vector, which serves as the 'sentence vector' representing the entire input sequence.","metadata":{}},{"cell_type":"markdown","source":"### Why only CLS token is required for classification, and not mean of other tokens:\n\nhttps://datascience.stackexchange.com/questions/77044/bert-transformer-why-bert-transformer-uses-cls-token-for-classification-inst\n\n\r\nThe CLS token helps with the NSP task on which BERT is trained (apart from MLM). The authors found it convenient to create a new hidden state at the start of a sentence, rather than taking the sentence average or other types of poolin\n\nIn essence, CLS token of the last layer has connections with all of the other tokens on the previous layer.. ","metadata":{}},{"cell_type":"markdown","source":"### DistilBERT layer + Simple NN Implementation (Tensorflow)\n\n1) BERT explained: https://jalammar.github.io/illustrated-bert/ \n2) BERT code: https://jalammar.github.io/a-visual-guide-to-using-bert-for-the-first-time/ (Pytorch implementation)","metadata":{}},{"cell_type":"code","source":"# pretrained BERT models have max 512 token\nmax_len = 512","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T09:08:29.121236Z","iopub.execute_input":"2024-11-24T09:08:29.121518Z","iopub.status.idle":"2024-11-24T09:08:29.125416Z","shell.execute_reply.started":"2024-11-24T09:08:29.121489Z","shell.execute_reply":"2024-11-24T09:08:29.124538Z"}},"outputs":[],"execution_count":41},{"cell_type":"code","source":"# reimport date\ntrain_df = pd.read_csv('/kaggle/input/jigsaw-multilingual-toxic-comment-classification/jigsaw-toxic-comment-train.csv')\nvalidation_df = pd.read_csv('/kaggle/input/jigsaw-multilingual-toxic-comment-classification/validation.csv')\ntest_df = pd.read_csv('/kaggle/input/jigsaw-multilingual-toxic-comment-classification/test.csv')\nsub_df = pd.read_csv('/kaggle/input/jigsaw-multilingual-toxic-comment-classification/sample_submission.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T09:08:29.126310Z","iopub.execute_input":"2024-11-24T09:08:29.126584Z","iopub.status.idle":"2024-11-24T09:08:32.114277Z","shell.execute_reply.started":"2024-11-24T09:08:29.126560Z","shell.execute_reply":"2024-11-24T09:08:32.113305Z"}},"outputs":[],"execution_count":42},{"cell_type":"markdown","source":"### Tokeniser","metadata":{}},{"cell_type":"code","source":"# load hugging face pretrained distilbert tokenizer\n# Other pretrained models:\n# - distilbert-base-uncased\n# - distilbert-base-cased\n\ntokenizer = transformers.DistilBertTokenizer.from_pretrained('distilbert-base-multilingual-cased')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T09:08:32.115404Z","iopub.execute_input":"2024-11-24T09:08:32.115684Z","iopub.status.idle":"2024-11-24T09:08:33.197878Z","shell.execute_reply.started":"2024-11-24T09:08:32.115659Z","shell.execute_reply":"2024-11-24T09:08:33.196890Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b7264f0007e1403696295aeae93ac171"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/996k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"afee07e0e89146fe933845f4f6dcf076"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.96M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5d166b4501a342dc9de719c864f8a526"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/466 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"147f33584bdc4b92846a5d6bf9f8292b"}},"metadata":{}}],"execution_count":43},{"cell_type":"code","source":"# Preprocess data: Tokenize and encode X_train, X_test\n\ndef preprocess_data(texts, max_len=512):\n    encodings = tokenizer(\n        texts.astype(str).tolist(),\n        truncation=True,\n        padding='max_length',\n        max_length=max_len,\n        return_tensors='tf'\n    )\n    \n    return encodings['input_ids'], encodings['attention_mask']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T09:08:33.198998Z","iopub.execute_input":"2024-11-24T09:08:33.199252Z","iopub.status.idle":"2024-11-24T09:08:33.204028Z","shell.execute_reply.started":"2024-11-24T09:08:33.199229Z","shell.execute_reply":"2024-11-24T09:08:33.203203Z"}},"outputs":[],"execution_count":44},{"cell_type":"code","source":"X_train_id, X_train_att_mask = preprocess_data(train_df['comment_text'], max_len)\nX_valid_id, X_valid_att_mask = preprocess_data(validation_df['comment_text'], max_len)\nX_test_id, X_test_att_mask = preprocess_data(test_df['content'], max_len)\n\ny_train = train_df['toxic'].values\ny_valid = validation_df['toxic'].values","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T09:08:33.205132Z","iopub.execute_input":"2024-11-24T09:08:33.205387Z","iopub.status.idle":"2024-11-24T09:13:55.186093Z","shell.execute_reply.started":"2024-11-24T09:08:33.205353Z","shell.execute_reply":"2024-11-24T09:13:55.185353Z"}},"outputs":[],"execution_count":45},{"cell_type":"markdown","source":"### transformer model output\n\n1. sequence_output ( [0] ): Last hidden state of the sequence.\n2. pooler_output ( [1] ): Pooler output (e.g., [CLS] token representation).\n3. hidden_states ( [2] ): Intermediate hidden states.\n4. attentions ( [3] ): Attention weights.","metadata":{}},{"cell_type":"markdown","source":"Discussion on attention mask for BERT models:\nhttps://ai.stackexchange.com/questions/28833/isnt-attention-mask-for-bert-model-useless\n\nBERT's original implementation was an encoder. Huggingface's implementation was both encoder and decoder. For a transformer to act as decoder, it requires:\n1. masking future tokens  == attention_mask\n2. cross attention based on \"supplied encoder representations\".","metadata":{}},{"cell_type":"code","source":"def transformer_model(transformer, max_len=512):\n\n    # input data feed in to transformer\n    input_ids = Input(\n        shape=(max_len,),\n        dtype=tf.int32,\n        name='input_ids' # assign a name to input layer\n    )\n\n    # attention mask is used to indicate padding, and prevent model from attending the token\n    attention_mask = Input(\n        shape=(max_len,),\n        dtype=tf.int32,\n        name = 'attention_mask'\n    )\n\n    # Lambda layer = customer function layer\n    bert_output = Lambda(\n        lambda x: transformer(input_ids = x[0], attention_mask= x[1]),\n        output_shape = (None, max_len, transformer.config.hidden_size)\n    )([input_ids, attention_mask])\n    \n    \n    sequence_output = bert_output[0] # last hidden state\n\n    cls_token = sequence_output[:,0,:] # all rows, only cls token, all vectors of cls token)\n    \n    outputs = Dense(1, activation='sigmoid')(cls_token)\n\n    model = Model(\n        inputs=[input_ids, attention_mask], \n        outputs = outputs\n    )\n\n    model.compile(\n        loss = 'binary_crossentropy',\n        optimizer = 'adam',\n        metrics = ['accuracy']\n    )\n\n    return model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T09:13:55.187146Z","iopub.execute_input":"2024-11-24T09:13:55.187430Z","iopub.status.idle":"2024-11-24T09:13:55.194187Z","shell.execute_reply.started":"2024-11-24T09:13:55.187398Z","shell.execute_reply":"2024-11-24T09:13:55.193308Z"}},"outputs":[],"execution_count":46},{"cell_type":"markdown","source":"### Instantiate DistilBERT model","metadata":{}},{"cell_type":"code","source":"transformer_layer = (\n    transformers.TFDistilBertModel\n    .from_pretrained('distilbert-base-multilingual-cased')\n)\n\nmodel = transformer_model(transformer_layer, max_len)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T09:13:55.195207Z","iopub.execute_input":"2024-11-24T09:13:55.195456Z","iopub.status.idle":"2024-11-24T09:13:59.279385Z","shell.execute_reply.started":"2024-11-24T09:13:55.195433Z","shell.execute_reply":"2024-11-24T09:13:59.278761Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/542M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"141d848a360545869681e2c0e268bdc3"}},"metadata":{}},{"name":"stderr","text":"Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFDistilBertModel: ['vocab_transform.weight', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_transform.bias', 'vocab_projector.bias']\n- This IS expected if you are initializing TFDistilBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing TFDistilBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\nAll the weights of TFDistilBertModel were initialized from the PyTorch model.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n","output_type":"stream"}],"execution_count":47},{"cell_type":"code","source":"model.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T09:13:59.280503Z","iopub.execute_input":"2024-11-24T09:13:59.280869Z","iopub.status.idle":"2024-11-24T09:13:59.300829Z","shell.execute_reply.started":"2024-11-24T09:13:59.280831Z","shell.execute_reply":"2024-11-24T09:13:59.300017Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"functional_14\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_14\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n│ input_ids           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ -                 │\n│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_mask      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ -                 │\n│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lambda (\u001b[38;5;33mLambda\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, │          \u001b[38;5;34m0\u001b[0m │ input_ids[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n│                     │ \u001b[38;5;34m768\u001b[0m)              │            │ attention_mask[\u001b[38;5;34m0\u001b[0m… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ get_item (\u001b[38;5;33mGetItem\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m768\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ lambda[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ get_item_1          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ get_item[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n│ (\u001b[38;5;33mGetItem\u001b[0m)           │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_4 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │        \u001b[38;5;34m769\u001b[0m │ get_item_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n│ input_ids           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_mask      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lambda (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_ids[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)              │            │ attention_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ get_item (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GetItem</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lambda[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ get_item_1          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ get_item[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GetItem</span>)           │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">769</span> │ get_item_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m769\u001b[0m (3.00 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">769</span> (3.00 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m769\u001b[0m (3.00 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">769</span> (3.00 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}}],"execution_count":48},{"cell_type":"markdown","source":"### Train model","metadata":{}},{"cell_type":"code","source":"epochs = 2\nbatch_size = 128\n\nmodel.fit(\n    [X_train_id, X_train_att_mask],\n    y_train,\n    validation_data = ([X_valid_id, X_valid_att_mask], y_valid), \n    epochs= epochs,\n    batch_size = batch_size\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T09:13:59.301823Z","iopub.execute_input":"2024-11-24T09:13:59.302044Z","iopub.status.idle":"2024-11-24T10:09:34.749216Z","shell.execute_reply.started":"2024-11-24T09:13:59.302022Z","shell.execute_reply":"2024-11-24T10:09:34.748383Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/2\n","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1732439645.694850      69 assert_op.cc:38] Ignoring Assert operator functional_14_1/lambda_1/tf_distil_bert_model/distilbert/embeddings/assert_less/Assert/Assert\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m1746/1747\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 916ms/step - accuracy: 0.8951 - loss: 0.2653","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1732441251.107630      70 assert_op.cc:38] Ignoring Assert operator functional_14_1/lambda_1/tf_distil_bert_model/distilbert/embeddings/assert_less/Assert/Assert\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m1747/1747\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 918ms/step - accuracy: 0.8951 - loss: 0.2653","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1732441256.086868      69 assert_op.cc:38] Ignoring Assert operator functional_14_1/lambda_1/tf_distil_bert_model/distilbert/embeddings/assert_less/Assert/Assert\nW0000 00:00:1732441313.971951      68 assert_op.cc:38] Ignoring Assert operator functional_14_1/lambda_1/tf_distil_bert_model/distilbert/embeddings/assert_less/Assert/Assert\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m1747/1747\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1678s\u001b[0m 954ms/step - accuracy: 0.8951 - loss: 0.2652 - val_accuracy: 0.8489 - val_loss: 0.4003\nEpoch 2/2\n\u001b[1m1747/1747\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1658s\u001b[0m 949ms/step - accuracy: 0.9221 - loss: 0.2045 - val_accuracy: 0.8487 - val_loss: 0.4039\n","output_type":"stream"},{"execution_count":49,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.history.History at 0x7a39a9e699f0>"},"metadata":{}}],"execution_count":49},{"cell_type":"markdown","source":"### Predict presence of toxic comments","metadata":{}},{"cell_type":"code","source":"predict =  model.predict([X_valid_id, X_valid_att_mask], verbose=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T10:09:34.750306Z","iopub.execute_input":"2024-11-24T10:09:34.750549Z","iopub.status.idle":"2024-11-24T10:10:34.749040Z","shell.execute_reply.started":"2024-11-24T10:09:34.750525Z","shell.execute_reply":"2024-11-24T10:10:34.748204Z"}},"outputs":[{"name":"stderr","text":"W0000 00:00:1732442975.654846      70 assert_op.cc:38] Ignoring Assert operator functional_14_1/lambda_1/tf_distil_bert_model/distilbert/embeddings/assert_less/Assert/Assert\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 229ms/step\n","output_type":"stream"}],"execution_count":50},{"cell_type":"code","source":"# append DistilBERT auc score\nauc_scores.append({'Model':'DistilBert', 'AUC_Score':round(roc_auc_score(y_valid,predict),4)})\nprint(f'auc: {roc_auc_score(y_valid,predict):.4f}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T10:10:34.750345Z","iopub.execute_input":"2024-11-24T10:10:34.750644Z","iopub.status.idle":"2024-11-24T10:10:34.764542Z","shell.execute_reply.started":"2024-11-24T10:10:34.750618Z","shell.execute_reply":"2024-11-24T10:10:34.763754Z"}},"outputs":[{"name":"stdout","text":"auc: 0.6765\n","output_type":"stream"}],"execution_count":51},{"cell_type":"code","source":"results = pd.DataFrame(auc_scores).sort_values(by='AUC_Score',ascending=False)\nresults","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T10:10:34.765543Z","iopub.execute_input":"2024-11-24T10:10:34.765884Z","iopub.status.idle":"2024-11-24T10:10:34.792324Z","shell.execute_reply.started":"2024-11-24T10:10:34.765840Z","shell.execute_reply":"2024-11-24T10:10:34.791583Z"}},"outputs":[{"execution_count":52,"output_type":"execute_result","data":{"text/plain":"            Model  AUC_Score\n2             GRU     0.9786\n3  Bi-Directional     0.9773\n1            LSTM     0.9769\n0       SimpleRnn     0.8893\n4      DistilBert     0.6765","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Model</th>\n      <th>AUC_Score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2</th>\n      <td>GRU</td>\n      <td>0.9786</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Bi-Directional</td>\n      <td>0.9773</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>LSTM</td>\n      <td>0.9769</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>SimpleRnn</td>\n      <td>0.8893</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>DistilBert</td>\n      <td>0.6765</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":52},{"cell_type":"markdown","source":"Further work:\n1. Sequence to Sequence models\n2. Pytorch implementation of DistilBERT\n3. Comparison to other models such as RoBERTa and DeBERTa","metadata":{}}]}